{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Ara Proje.ipynb",
   "provenance": [
    {
     "file_id": "14GjVP0NK5D9UMfAlCwFjFzNbgQDq__Tf",
     "timestamp": 1583842388047
    },
    {
     "file_id": "1C0THUULccnCE_ffmtH7tRxM5PbqHmMBd",
     "timestamp": 1583826486247
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cffc9ee220225be8f8651f6b360c9284ecb94bcb",
    "id": "-prsqHQ1F21a",
    "colab_type": "text"
   },
   "source": [
    "Check out corresponding Medium article:\n",
    "\n",
    "[Face Generator - Generating Artificial Faces with Machine Learning ](https://towardsdatascience.com/face-generator-generating-artificial-faces-with-machine-learning-9e8c3d6c1ead)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kcpVMIn8NyEC",
    "colab_type": "code",
    "outputId": "fef0dc6a-4e3b-448a-8921-8e8bbd717c52",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1585041746534,
     "user_tz": -240,
     "elapsed": 16233,
     "user": {
      "displayName": "Nihad Guluzade",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gja_QX65VcSFk1jInHoHjAlII9EtW_67ievZE3d=s64",
      "userId": "08803254641674605624"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    }
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "路路路路路路路路路路\n",
      "Mounted at /content/drive\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "_uuid": "69b13cbca3614de202fe1b5de41e3f2166b4067b",
    "colab_type": "code",
    "id": "CAkj8P6m-AJA",
    "outputId": "cfbd46a5-af11-4103-bc4c-6b9c041969e3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1585041785117,
     "user_tz": -240,
     "elapsed": 6143,
     "user": {
      "displayName": "Nihad Guluzade",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gja_QX65VcSFk1jInHoHjAlII9EtW_67ievZE3d=s64",
      "userId": "08803254641674605624"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    }
   },
   "source": [
    "import os\n",
    "import time\n",
    "%tensorflow_version 1.x\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import datetime\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "_uuid": "269879e2953fb178303e03dcbcbf3f52ff2dee7b",
    "colab_type": "code",
    "id": "fdzDJyNa-dDA",
    "colab": {}
   },
   "source": [
    "def generator(z, output_channel_dim, training):\n",
    "    with tf.variable_scope(\"generator\", reuse= not training):\n",
    "        \n",
    "        # 8x8x1024\n",
    "        fully_connected = tf.layers.dense(z, 8*8*1024)\n",
    "        fully_connected = tf.reshape(fully_connected, (-1, 8, 8, 1024))\n",
    "        fully_connected = tf.nn.leaky_relu(fully_connected)\n",
    "\n",
    "        # 8x8x1024 -> 16x16x512\n",
    "        trans_conv1 = tf.layers.conv2d_transpose(inputs=fully_connected,\n",
    "                                                 filters=512,\n",
    "                                                 kernel_size=[5,5],\n",
    "                                                 strides=[2,2],\n",
    "                                                 padding=\"SAME\",\n",
    "                                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
    "                                                 name=\"trans_conv1\")\n",
    "        batch_trans_conv1 = tf.layers.batch_normalization(inputs = trans_conv1,\n",
    "                                                          training=training,\n",
    "                                                          epsilon=EPSILON,\n",
    "                                                          name=\"batch_trans_conv1\")\n",
    "        trans_conv1_out = tf.nn.leaky_relu(batch_trans_conv1,\n",
    "                                           name=\"trans_conv1_out\")\n",
    "        \n",
    "        # 16x16x512 -> 32x32x256\n",
    "        trans_conv2 = tf.layers.conv2d_transpose(inputs=trans_conv1_out,\n",
    "                                                 filters=256,\n",
    "                                                 kernel_size=[5,5],\n",
    "                                                 strides=[2,2],\n",
    "                                                 padding=\"SAME\",\n",
    "                                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
    "                                                 name=\"trans_conv2\")\n",
    "        batch_trans_conv2 = tf.layers.batch_normalization(inputs = trans_conv2,\n",
    "                                                          training=training,\n",
    "                                                          epsilon=EPSILON,\n",
    "                                                          name=\"batch_trans_conv2\")\n",
    "        trans_conv2_out = tf.nn.leaky_relu(batch_trans_conv2,\n",
    "                                           name=\"trans_conv2_out\")\n",
    "        \n",
    "        # 32x32x256 -> 64x64x128\n",
    "        trans_conv3 = tf.layers.conv2d_transpose(inputs=trans_conv2_out,\n",
    "                                                 filters=128,\n",
    "                                                 kernel_size=[5,5],\n",
    "                                                 strides=[2,2],\n",
    "                                                 padding=\"SAME\",\n",
    "                                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
    "                                                 name=\"trans_conv3\")\n",
    "        batch_trans_conv3 = tf.layers.batch_normalization(inputs = trans_conv3,\n",
    "                                                          training=training,\n",
    "                                                          epsilon=EPSILON,\n",
    "                                                          name=\"batch_trans_conv3\")\n",
    "        trans_conv3_out = tf.nn.leaky_relu(batch_trans_conv3,\n",
    "                                           name=\"trans_conv3_out\")\n",
    "        \n",
    "        # 64x64x128 -> 128x128x64\n",
    "        trans_conv4 = tf.layers.conv2d_transpose(inputs=trans_conv3_out,\n",
    "                                                 filters=64,\n",
    "                                                 kernel_size=[5,5],\n",
    "                                                 strides=[2,2],\n",
    "                                                 padding=\"SAME\",\n",
    "                                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
    "                                                 name=\"trans_conv4\")\n",
    "        batch_trans_conv4 = tf.layers.batch_normalization(inputs = trans_conv4,\n",
    "                                                          training=training,\n",
    "                                                          epsilon=EPSILON,\n",
    "                                                          name=\"batch_trans_conv4\")\n",
    "        trans_conv4_out = tf.nn.leaky_relu(batch_trans_conv4,\n",
    "                                           name=\"trans_conv4_out\")\n",
    "        \n",
    "        # 128x128x64 -> 128x128x3\n",
    "        logits = tf.layers.conv2d_transpose(inputs=trans_conv4_out,\n",
    "                                            filters=3,\n",
    "                                            kernel_size=[5,5],\n",
    "                                            strides=[1,1],\n",
    "                                            padding=\"SAME\",\n",
    "                                            kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
    "                                            name=\"logits\")\n",
    "        out = tf.tanh(logits, name=\"out\")\n",
    "        return out"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "_uuid": "fd0ecc8bd98a8bab6d8cd0e51aed1a0dbc500f79",
    "colab_type": "code",
    "id": "1dIfUSZF-qeL",
    "colab": {}
   },
   "source": [
    "def discriminator(x, reuse):\n",
    "    with tf.variable_scope(\"discriminator\", reuse=reuse): \n",
    "        \n",
    "        # 128*128*3 -> 64x64x64 \n",
    "        conv1 = tf.layers.conv2d(inputs=x,\n",
    "                                 filters=64,\n",
    "                                 kernel_size=[5,5],\n",
    "                                 strides=[2,2],\n",
    "                                 padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
    "                                 name='conv1')\n",
    "        batch_norm1 = tf.layers.batch_normalization(conv1,\n",
    "                                                    training=True,\n",
    "                                                    epsilon=EPSILON,\n",
    "                                                    name='batch_norm1')\n",
    "        conv1_out = tf.nn.leaky_relu(batch_norm1,\n",
    "                                     name=\"conv1_out\")\n",
    "        \n",
    "        # 64x64x64-> 32x32x128 \n",
    "        conv2 = tf.layers.conv2d(inputs=conv1_out,\n",
    "                                 filters=128,\n",
    "                                 kernel_size=[5, 5],\n",
    "                                 strides=[2, 2],\n",
    "                                 padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
    "                                 name='conv2')\n",
    "        batch_norm2 = tf.layers.batch_normalization(conv2,\n",
    "                                                    training=True,\n",
    "                                                    epsilon=EPSILON,\n",
    "                                                    name='batch_norm2')\n",
    "        conv2_out = tf.nn.leaky_relu(batch_norm2,\n",
    "                                     name=\"conv2_out\")\n",
    "        \n",
    "        # 32x32x128 -> 16x16x256  \n",
    "        conv3 = tf.layers.conv2d(inputs=conv2_out,\n",
    "                                 filters=256,\n",
    "                                 kernel_size=[5, 5],\n",
    "                                 strides=[2, 2],\n",
    "                                 padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
    "                                 name='conv3')\n",
    "        batch_norm3 = tf.layers.batch_normalization(conv3,\n",
    "                                                    training=True,\n",
    "                                                    epsilon=EPSILON,\n",
    "                                                    name='batch_norm3')\n",
    "        conv3_out = tf.nn.leaky_relu(batch_norm3,\n",
    "                                     name=\"conv3_out\")\n",
    "        \n",
    "        # 16x16x256 -> 16x16x512\n",
    "        conv4 = tf.layers.conv2d(inputs=conv3_out,\n",
    "                                 filters=512,\n",
    "                                 kernel_size=[5, 5],\n",
    "                                 strides=[1, 1],\n",
    "                                 padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
    "                                 name='conv4')\n",
    "        batch_norm4 = tf.layers.batch_normalization(conv4,\n",
    "                                                    training=True,\n",
    "                                                    epsilon=EPSILON,\n",
    "                                                    name='batch_norm4')\n",
    "        conv4_out = tf.nn.leaky_relu(batch_norm4,\n",
    "                                     name=\"conv4_out\")\n",
    "        \n",
    "        # 16x16x512 -> 8x8x1024\n",
    "        conv5 = tf.layers.conv2d(inputs=conv4_out,\n",
    "                                filters=1024,\n",
    "                                kernel_size=[5, 5],\n",
    "                                strides=[2, 2],\n",
    "                                padding=\"SAME\",\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=WEIGHT_INIT_STDDEV),\n",
    "                                name='conv5')\n",
    "        batch_norm5 = tf.layers.batch_normalization(conv5,\n",
    "                                                    training=True,\n",
    "                                                    epsilon=EPSILON,\n",
    "                                                    name='batch_norm5')\n",
    "        conv5_out = tf.nn.leaky_relu(batch_norm5,\n",
    "                                     name=\"conv5_out\")\n",
    "\n",
    "        flatten = tf.reshape(conv5_out, (-1, 8*8*1024))\n",
    "        logits = tf.layers.dense(inputs=flatten,\n",
    "                                 units=1,\n",
    "                                 activation=None)\n",
    "        out = tf.sigmoid(logits)\n",
    "        return out, logits\n",
    "        "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "_uuid": "b24938d4786878c0df90b7cedab93568d01fba09",
    "colab_type": "code",
    "id": "PgEg-7ce-qjv",
    "colab": {}
   },
   "source": [
    "def model_loss(input_real, input_z, output_channel_dim):\n",
    "    g_model = generator(input_z, output_channel_dim, True)\n",
    "\n",
    "    noisy_input_real = input_real + tf.random_normal(shape=tf.shape(input_real),\n",
    "                                                     mean=0.0,\n",
    "                                                     stddev=random.uniform(0.0, 0.1),\n",
    "                                                     dtype=tf.float32)\n",
    "    \n",
    "    d_model_real, d_logits_real = discriminator(noisy_input_real, reuse=False)\n",
    "    d_model_fake, d_logits_fake = discriminator(g_model, reuse=True)\n",
    "    \n",
    "    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,\n",
    "                                                                         labels=tf.ones_like(d_model_real)*random.uniform(0.9, 1.0)))\n",
    "    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                                         labels=tf.zeros_like(d_model_fake)))\n",
    "    d_loss = tf.reduce_mean(0.5 * (d_loss_real + d_loss_fake))\n",
    "    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                                    labels=tf.ones_like(d_model_fake)))\n",
    "    return d_loss, g_loss"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "_uuid": "7dbc0c421979ed07e96b97dd89bb6371e24912ae",
    "colab_type": "code",
    "id": "sh0wH3f1-qrI",
    "colab": {}
   },
   "source": [
    "def model_optimizers(d_loss, g_loss):\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith(\"generator\")]\n",
    "    d_vars = [var for var in t_vars if var.name.startswith(\"discriminator\")]\n",
    "    \n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    gen_updates = [op for op in update_ops if op.name.startswith('generator') or op.name.startswith('discriminator')]\n",
    "    \n",
    "    with tf.control_dependencies(gen_updates):\n",
    "        d_train_opt = tf.train.AdamOptimizer(learning_rate=LR_D, beta1=BETA1).minimize(d_loss, var_list=d_vars)\n",
    "        g_train_opt = tf.train.AdamOptimizer(learning_rate=LR_G, beta1=BETA1).minimize(g_loss, var_list=g_vars)  \n",
    "    return d_train_opt, g_train_opt"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "_uuid": "98640bff572fd14dacb3c133bee04a3019f139dc",
    "colab_type": "code",
    "id": "Y3ic2whC-i1Q",
    "colab": {}
   },
   "source": [
    "def model_inputs(real_dim, z_dim):\n",
    "    inputs_real = tf.placeholder(tf.float32, (None, *real_dim), name='inputs_real')\n",
    "    inputs_z = tf.placeholder(tf.float32, (None, z_dim), name=\"input_z\")\n",
    "    learning_rate_G = tf.placeholder(tf.float32, name=\"lr_g\")\n",
    "    learning_rate_D = tf.placeholder(tf.float32, name=\"lr_d\")\n",
    "    return inputs_real, inputs_z, learning_rate_G, learning_rate_D"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "_uuid": "f50ecde09443ec43074c916c197c1bddec783ef1",
    "colab_type": "code",
    "id": "cqsjGWY0-i9m",
    "colab": {}
   },
   "source": [
    "def show_samples(sample_images, name, epoch):\n",
    "    figure, axes = plt.subplots(1, len(sample_images), figsize = (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    for index, axis in enumerate(axes):\n",
    "        axis.axis('off')\n",
    "        image_array = sample_images[index]\n",
    "        axis.imshow(image_array)\n",
    "        image = Image.fromarray(image_array)\n",
    "        #image.save(name+\"_\"+str(epoch)+\"_\"+str(index)+\".png\") \n",
    "    plt.savefig(name+\"_\"+str(epoch)+\".png\", bbox_inches='tight', pad_inches=0)\n",
    "    #plt.show()\n",
    "    plt.close()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "_uuid": "99f792f2bccdc7b70511bde7b276e5fe72ebd38e",
    "colab_type": "code",
    "id": "ABruaSXz-dLn",
    "colab": {}
   },
   "source": [
    "def test(sess, input_z, out_channel_dim, epoch):\n",
    "    example_z = np.random.uniform(-1, 1, size=[SAMPLES_TO_SHOW, input_z.get_shape().as_list()[-1]])\n",
    "    samples = sess.run(generator(input_z, out_channel_dim, False), feed_dict={input_z: example_z})\n",
    "    sample_images = [((sample + 1.0) * 127.5).astype(np.uint8) for sample in samples]\n",
    "    show_samples(sample_images, OUTPUT_DIR + \"samples/samples\", epoch)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "_uuid": "80caaf83ab3ce84c96f2d50f623138fbeb6b5a36",
    "colab_type": "code",
    "id": "7jlynGxL-KM5",
    "colab": {}
   },
   "source": [
    "def summarize_epoch(epoch, sess, d_losses, g_losses, input_z, data_shape):\n",
    "    print(\"\\nEpoch {}/{}\".format(epoch, EPOCHS),\n",
    "          \"\\nD Loss: {:.5f}\".format(np.mean(d_losses[-MINIBATCH_SIZE:])),\n",
    "          \"\\nG Loss: {:.5f}\".format(np.mean(g_losses[-MINIBATCH_SIZE:])))\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(d_losses, label='Discriminator', alpha=0.6)\n",
    "    plt.plot(g_losses, label='Generator', alpha=0.6)\n",
    "    plt.title(\"Losses\")\n",
    "    plt.legend()\n",
    "    if ((epoch + 1) % 100 == 0) or (epoch == EPOCHS - 1):\n",
    "        plt.savefig(OUTPUT_DIR + \"losses/\" + \"losses_\" + str(epoch) + \".png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    test(sess, input_z, data_shape[3], epoch)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "_uuid": "b473c2d608c518b083e380afb4abc59918649f49",
    "colab_type": "code",
    "id": "qREM80mB-KVB",
    "colab": {}
   },
   "source": [
    "def get_batch(dataset):\n",
    "    files = random.sample(dataset, BATCH_SIZE)\n",
    "    batch = []\n",
    "    for file in files:\n",
    "        if random.choice([True, False]):\n",
    "            batch.append(np.asarray(Image.open(file).transpose(Image.FLIP_LEFT_RIGHT)))\n",
    "        else:\n",
    "            batch.append(np.asarray(Image.open(file)))                     \n",
    "    batch = np.asarray(batch)\n",
    "    normalized_batch = (batch / 127.5) - 1.0\n",
    "    return normalized_batch, files"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "_uuid": "3157b1180042f57417164303eb04ea0d8694a23c",
    "colab_type": "code",
    "id": "zmfeOwQl-KYr",
    "colab": {}
   },
   "source": [
    "def train(data_shape, epoch, checkpoint_path):\n",
    "    input_images, input_z, lr_G, lr_D = model_inputs(data_shape[1:], NOISE_SIZE)\n",
    "    d_loss, g_loss = model_loss(input_images, input_z, data_shape[3])\n",
    "    d_opt, g_opt = model_optimizers(d_loss, g_loss)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "        if checkpoint_path is not None:\n",
    "            saver.restore(sess, checkpoint_path)\n",
    "            \n",
    "        iteration = 0\n",
    "        d_losses = []\n",
    "        g_losses = []\n",
    "        \n",
    "        for epoch in range(EPOCH, EPOCHS):        \n",
    "            epoch_dataset = DATASET.copy()\n",
    "            \n",
    "            for i in range(MINIBATCH_SIZE):\n",
    "                iteration_start_time = time.time()\n",
    "                iteration += 1\n",
    "                batch_images, used_files = get_batch(epoch_dataset)\n",
    "                [epoch_dataset.remove(file) for file in used_files]\n",
    "                \n",
    "                batch_z = np.random.uniform(-1, 1, size=(BATCH_SIZE, NOISE_SIZE))\n",
    "                _ = sess.run(d_opt, feed_dict={input_images: batch_images, input_z: batch_z, lr_D: LR_D})\n",
    "                d_losses.append(d_loss.eval({input_z: batch_z, input_images: batch_images}))\n",
    "                \n",
    "                _ = sess.run(g_opt, feed_dict={input_images: batch_images, input_z: batch_z, lr_G: LR_G})\n",
    "                g_losses.append(g_loss.eval({input_z: batch_z}))\n",
    "                \n",
    "                elapsed_time = round(time.time()-iteration_start_time, 3)\n",
    "                remaining_files = len(epoch_dataset)\n",
    "                print(\"\\rEpoch: \" + str(epoch) +\n",
    "                      \", iteration: \" + str(iteration) + \n",
    "                      \", d_loss: \" + str(round(d_losses[-1], 3)) +\n",
    "                      \", g_loss: \" + str(round(g_losses[-1], 3)) +\n",
    "                      \", duration: \" + str(elapsed_time) + \n",
    "                      \", minutes remaining: \" + str(round(remaining_files/BATCH_SIZE*elapsed_time/60, 1)) +\n",
    "                      \", remaining files in batch: \" + str(remaining_files)\n",
    "                      , sep=' ', end=' ', flush=True)\n",
    "            summarize_epoch(epoch, sess, d_losses, g_losses, input_z, data_shape)\n",
    "            if (epoch > 0):\n",
    "                if (epoch == EPOCHS - 1):\n",
    "                    saver.save(sess, OUTPUT_DIR + \"models/\" + \"model_\" + str(epoch) + \".ckpt\")\n",
    "                elif ((EPOCHS < 100) and ((epoch + 1) % 5 == 0)) or \\\n",
    "                    ((100 <= EPOCHS and EPOCHS < 500) and ((epoch + 1) % 50 == 0)) or \\\n",
    "                    (EPOCHS >= 500 and (epoch + 1) % 30 == 0):\n",
    "                    saver.save(sess, OUTPUT_DIR + \"models/\" + \"model_\" + str(epoch) + \".ckpt\")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlBwaQJNdxs_",
    "colab_type": "text"
   },
   "source": [
    "### Create Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def gen_samples(sample_images, name, iteration):\n",
    "    figure, axes = plt.subplots(1, len(sample_images), figsize = (IMAGE_WIDTH, IMAGE_HEIGHT), squeeze=False)\n",
    "    figure = plt.gcf()\n",
    "    DPI = figure.get_dpi()\n",
    "    figure.set_size_inches(170.0/float(DPI),170.0/float(DPI))\n",
    "    plt.axis('off')\n",
    "    image_array = sample_images[0]\n",
    "    plt.imshow(image_array)\n",
    "    image = Image.fromarray(image_array)\n",
    "    plt.savefig(name + f\"_{iteration}.png\", bbox_inches='tight', pad_inches=0)\n",
    "    #print(name + f\"_{iteration}.png saved.\")\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def gen_test(sess, input_z, out_channel_dim, iteration):\n",
    "    example_z = np.random.uniform(-1, 1, size=[SAMPLES_TO_SHOW, input_z.get_shape().as_list()[-1]])\n",
    "    samples = sess.run(generator(input_z, out_channel_dim, False), feed_dict={input_z: example_z})\n",
    "    sample_images = [((sample + 1.0) * 127.5).astype(np.uint8) for sample in samples]\n",
    "    gen_samples(sample_images, DRIVE_DIR + \"images/\", iteration)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def augment(iterations, checkpoint_path):\n",
    "    input_images, input_z, lr_G, lr_D = model_inputs((IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS), NOISE_SIZE)\n",
    "    d_loss, g_loss = model_loss(input_images, input_z, IMAGE_CHANNELS)\n",
    "    d_opt, g_opt = model_optimizers(d_loss, g_loss)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        if checkpoint_path is not None:\n",
    "            saver.restore(sess, checkpoint_path)\n",
    "        \n",
    "        for i in range(iterations):        \n",
    "            gen_test(sess, input_z, IMAGE_CHANNELS, i)\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating samples\n",
    "model = DRIVE_DIR + '/models/37/model_1999.ckpt' # add model number\n",
    "with tf.Graph().as_default():\n",
    "    augment(iterations=1000, checkpoint_path=model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "_uuid": "f62171dc195cc18db6087c24180487f17f6035e7",
    "colab_type": "code",
    "id": "_4GB3G-D-Key",
    "colab": {}
   },
   "source": [
    "import os\n",
    "import numpy\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "# Hyperparameters\n",
    "IMAGE_SIZE = 128\n",
    "NOISE_SIZE = 128\n",
    "LR_D = 0.00004\n",
    "LR_G = 0.00004\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 2200\n",
    "EPOCHS = 2500\n",
    "BETA1 = 0.9\n",
    "WEIGHT_INIT_STDDEV = 0.002\n",
    "EPSILON = 0.005\n",
    "SAMPLES_TO_SHOW = 5 # 1 if generating samples\n",
    "\n",
    "checkpoint = DRIVE_DIR + f'outputs-46/models/model_{EPOCH - 1}.ckpt' # add model number\n",
    "\n",
    "# Resize images to 128x128, channel 3 because colored\n",
    "IMAGE_WIDTH, IMAGE_HEIGHT = 128, 128\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "DRIVE_DIR = '/content/drive/My Drive/Colab Notebooks/datasets/sperm_datasets/SpermDataset/' # Google Drive path\n",
    "DATASET_DIR = DRIVE_DIR + 'SMIDS/Abnormal_Sperm/' # choose dataset path\n",
    "\n",
    "DATA_TXT_NAME = 'data_smids_abnormal.txt' # choose dataset txt name\n",
    "CROPPED_FOLDER = 'cropped_smids_abnormal/' # choose cropped folder name\n",
    "OUTPUTS_FOLDER = 'outputs-46/'\n",
    "SAMPLES_FOLDER = 'samples/' # ! do not change\n",
    "LOSSES_FOLDER = 'losses/' # ! do not change\n",
    "MODELS_FOLDER = 'models/' # ! do not change\n",
    "\n",
    "TXT_FILE = open(DATA_TXT_NAME, \"w\")\n",
    "TXT_PATH = DRIVE_DIR + DATA_TXT_NAME\n",
    "\n",
    "cropped_full_path = os.path.join(DRIVE_DIR, CROPPED_FOLDER)\n",
    "outputs_full_path = os.path.join(DRIVE_DIR, OUTPUTS_FOLDER)\n",
    "\n",
    "save_dir = cropped_full_path\n",
    "\n",
    "if not os.path.exists(DATASET_DIR):\n",
    "  print(f\"{DATASET_DIR} does not exists.\")\n",
    "else:\n",
    "  print(\"Dataset found.\")\n",
    "if not os.path.exists(cropped_full_path):\n",
    "  os.mkdir(cropped_full_path)\n",
    "  print(f\"{CROPPED_FOLDER} created.\")\n",
    "else:\n",
    "  print(f\"{CROPPED_FOLDER} exists.\")\n",
    "if not os.path.exists(outputs_full_path):\n",
    "  os.mkdir(outputs_full_path)\n",
    "  os.mkdir(outputs_full_path + SAMPLES_FOLDER)\n",
    "  os.mkdir(outputs_full_path + LOSSES_FOLDER)\n",
    "  os.mkdir(outputs_full_path + MODELS_FOLDER)\n",
    "  print(f\"{OUTPUTS_FOLDER}, {SAMPLES_FOLDER}, {LOSSES_FOLDER}, {MODELS_FOLDER} created.\")\n",
    "else:\n",
    "  print(\"outputs folders exist.\")\n",
    "  "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cropping"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O6WEpRXLFE3w",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# run only if there're no cropped data and txt\n",
    "\n",
    "# write data names to txt file\n",
    "for filename in os.listdir(DATASET_DIR):\n",
    "  TXT_FILE.write(filename)\n",
    "  TXT_FILE.write(\"\\n\")\n",
    "TXT_FILE.close()\n",
    "\n",
    "shutil.move(DATA_TXT_NAME, TXT_PATH) # move file to drive\n",
    "\n",
    "# Iterating over the images inside the directory and resizing them using\n",
    "# Pillow's resize method\n",
    "print('resizing...')\n",
    "\n",
    "for filename in os.listdir(DATASET_DIR):\n",
    "  path = os.path.join(DATASET_DIR, filename)\n",
    "  if not (os.path.isdir(path)):\n",
    "    image = Image.open(path).resize((IMAGE_WIDTH, IMAGE_HEIGHT), Image.ANTIALIAS)\n",
    "    new_file_name = os.path.join(save_dir, filename)\n",
    "    image.save(new_file_name)\n",
    "print(\"Cropping finished.\")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9wVsJcbQjUCt",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "DATASET_LIST_PATH = TXT_PATH\n",
    "INPUT_DATA_DIR = DRIVE_DIR + CROPPED_FOLDER\n",
    "OUTPUT_DIR = DRIVE_DIR + OUTPUTS_FOLDER # output to drive\n",
    "DATASET = [INPUT_DATA_DIR + str(line).rstrip() for line in open(DATASET_LIST_PATH,\"r\")]\n",
    "DATASET_SIZE = len(DATASET) \n",
    "MINIBATCH_SIZE = DATASET_SIZE // BATCH_SIZE\n",
    "print(f'Dataset length: {len(DATASET)}')"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "_uuid": "334430e166a0ef81a81cb252e375a7250b92eb17",
    "colab_type": "code",
    "id": "LZ8A7ql4-In_",
    "colab": {}
   },
   "source": [
    "# Training\n",
    "with tf.Graph().as_default():\n",
    "    train(data_shape=(DATASET_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "          epoch=EPOCH,\n",
    "          checkpoint_path=None) # checkpoint_path=checkpoint if model exists"
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}